# Airflow 사용시 주의점
- Airflow와 타임존
    - airflow.cfg에서 airflow에서 사용되는 timezone을 default_timezone으로 변경 가능
    - default_ui_timezone은 UI에서 보이는 시간만 변경
    - execution_date, 로그에 기록된 시간은 항상 UTC를 따름
    - UTC로 일관되게 사용하는 것을 권장
- Airflow는 dags 폴더의 파일과 하위 폴더를 스캔
    - 테스트 코드를 dags 폴더에 저장하지 않도록 주의
    - 모든 파이썬 코드를 실행 후 dag인지 아닌지 파악함

# Primary Key Uniqueness 보장
- 테이블에서 하나의 레코드를 유일하게 지칭할 수 있는 필드
- 하나의 필드가 일반적이지만 다수의 필드를 사용하는 경우도 있음
- CREATE TABLE 사용시 지정
- 일반적으로 관계형 DB 시스템이 중복 존재를 막아주지만 DW에서는 제공하지 않음
- DW에서는 Primary key 유일성을 보장할 때 메모리와 시간이 들기 때문에 보장해주지 않음
- Incremental Update를 할 떄 주의해야 함

# Upsert
- Primary Key를 기준으로 존재하는 레코드라면 새 정보로 수정
- 존재하지 않으면 새 레코드로 적재
- DW마다 UPSERT를 효율적으로 해주는 문법을 지원함

# Backfill
- 실패한 데이터 파이프라인을 재실행 혹은 읽어온 데이터들의 문제로 다시 읽어와야 하는 경우
- Full Refresh를 할 때는 필요가 없음
- Incremental Update시에만 의미가 있음
- Incremental Update는 효율성이 좋지만 운영/유지보수의 난이도가 올라가서 Full Refresh를 추천
- Airflow 변수
    - start_date : DAG가 처음 실행되는 날짜가 아닌 DAG가 처음 읽어와야 하는 데이터의 날짜/시간. 실제 첫 실행 날짜는 start_date + DAG 실행 주기
    - execution_date : DAG가 읽어와야하는 데이터의 날짜와 시간
    - catchup : DAG가 처음 활성화된 시점이 start_date보다 미래라면 그 사이 실행되지 않은 것들을 결정하는 파라미터. True가 디폴트
    - end_date : 보통 필요하지 않으며 Backfill을 날짜 범위에 대해 하는 경우에만 필요 
- Backfill 명령어
    - `airflow dags backfill -s startdate -e enddate`
    - enddate는 포함되지 않음, enddate 전날까지 
    - catchUp이 True로 설정되어있어야 함
    - execution_date를 사용해서 Incremental update가 구현되어있을 때 가능
    - 날짜 순서대로 실행하고 싶다면 DAG default_args에 `'depends_on_past' : True` 입력


# MySQL 테이블에서 incremental update 할 때 주의사항
- 테이블을 생성하거나 변경될 때 created, modified라는 timestamp 정보로 데이터를 업데이트 가능
- 자료가 삭제될 때 실제로 삭제되면 incremental update가 불가능
- 따라서 자료를 실제로 삭제하지 않고 deteled라는 boolean type 표를 이용해 표시해야함
- S3ToRedshiftOperator 사용 방법
    - mothod 파라미터를 UPSERT 지정
    - upsert_keys 파라미터로 Primary key 지정
    - `SELECT * FROM talbe_name WHERE DATE(modified) = DATE(execution_date)`로 SQL 설정

# airflow 버전 제한사항 확인
- branch에 contraints를 검색하여 각 버전별 모듈 버전 제한 확인