# Airflow 프로그램
- PythonOperator
    - Airflow task에 python 함수를 쓸 수 있게 해주는 라이브러리
    - `dag` : 속해있는 dag입력
    - `task_id` : id로 사용할 이름
    - `python_callable` : 실행할 파이썬 함수
    - `params` : 딕셔너리 형태로 파이썬 함수 인자 사용
    - `airflow.decorators.task`를 쓰면 데코레이터로 간단하게 활용 가능
- Connections
    - AWS 이용시 hostname, port number, 사용자 정보 등 중요한 정보를 하드코딩 하지 않고 외부에 별도로 저장할 수 있게 해준다
    - Postgres connection정보 혹은 Redshift 등의 정보를 저장한다
    - Web UI > Admin > Connections에서 설정 가능
- Variables
    - API 키를 저장했다가 사용하는 방법
    - Web UI > Admin > Variables에서 설정 가능
    - docker compose yml 파일에서도 설정 가능
        - 웹 UI에서는 보이지 않음
        - `docker exec -it container이름 airflow variables get 변수이름`으로 확인 가능
    - `airflow variables(or connections) export(or import) filename`으로 파일로 export import 가능
- Xcom
    - PythonOperator의 출력값이 다음 task의 입력값이 되도록 하는 방법
    - 태스크(Operator)들 간에 데이터를 주고 받기 위한 방식
    - 하나의 Operator의 리턴값을 다른 Operator에서 읽어가는 형태
    - Airflow 메타 데이터 DB에 저장되기 때문에 큰 데이터를 주고 받는데는 사용 불가
    - 큰 데이터의 경우 S3등에 로드하고 그 위치를 넘기는 것이 일반적