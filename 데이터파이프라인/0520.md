# 데이터 파이프라인 (ETL)
- ETL : Extract, Transform, Load
- Data Workflow, DAG(Directed Acyclic Graph) 등으로 부름
- ELT : 데이터 웨어하우스 내부 데이터를 조작해서 새로운 데이터를 만드는 프로세스, 데이터 분석가들이 많이 수행, DBT를 많이 사용함
- 데이터 시스템 흐름
    1. 데이터 소스
    2. Data Lake : S3와 같은 스토리지
    3. Data Transforms : Spark, Athena(AWS의 PrestoSQL 기반 빅데이터 데이터 변환 프레임웍) 등을 사용해서 Data Lake의 데이터를 정재해서 DW에 적재
    4. DW / DM (Data Mart)
- 데이터 소스로부터 목적지로 복사하는 작업
- 코딩(파이썬 혹은 스칼라) 혹은 SQL을 통해 이뤄짐
- 목적지는 DW가 됨

# 데이터 파이프라인 종류
- Raw Data ETL Jobs
    1. 내부(같은 회사의 시스템) 혹은 외부(회사 밖)에 있는 데이터 소스에서 데이터를 읽는다 (많은 경우 API 사용)
    2. 적당한 데이터 포맷으로 변환 (데이터 크기가 클 경우 Spark등이 필요)
    3. 데이터 웨어하우스 로드
- Summary/Report Jobs (ELT)
    1. DW(혹은 DL)에서 데이터를 읽어 다시 DW에 쓰는 ETL
    2. Raw Data를 읽어 일종의 리포트 형태나 Summary 형태의 테이블을 다시 만드는 용도
    3. 특수한 형태로 AB 테스트 결과를 분석하는 데이터 파이프라인도 존재
- Production Data Jobs
    1. DW로부터 데이터를 읽어 다른 Storage(프로덕션 환경)로 쓰는 ETL
        - 써머리 정보가 프로덕션 환경에서 성능 이유로 필요한 경유
        - 머신러닝 모델에서 필요한 피쳐들을 미리 계산하는 경우
    2. 타겟 스토리지 예시
        - Cassandra/Hbase/DynamoDB와 같은 NoSQL
        - MySQL과 같은 관계형 DB
        - Redis/Memcache와 같은 캐시
        - ElasticSearch와 같은 검색엔진

# 데이터 파이프라인을 만들 때 고려할 점
- 멱등성을 보장
    - 데이터 파이프라인을 다수 실행해도 최종 테이블 내용이 달라지지 않아야함
    - 중복 데이터가 생기지 않도록 해야함
    - 중간에 오류가 생성될 경우 전체가 다 실패해야 함 : 트랜잭션 필요
- Backfill이 쉬워야 함 : 과거 데이터를 다시 채우는 과정
- 데이터 파이프라인의 입출력을 문서화
    - 데이터 리니지가 중요
    - 자료 흐림이 명확해야 파이프라인 수정 시 문제 발생하지 않음

# Airflow
- Airbnb에서 시작된 오픈소스 프로젝트로 파이썬으로 작성된 데이터 파이프라인 (ETL) 프레임웍
- 데이터 파이프라인 스케쥴링 지원
- 웹 UI 제공
- 데이터 파이프라인을 DAG(Directed Acyclic Graph)라고 함
    - 태스크로 구성, ex: Extract, Transform, Load
    - 태스크는 airflow의 오퍼레이터로 만들어짐
    - Redshift writing, Postgres query, S3 Read/Write, Hive query, Spark job, shell scrip 등
- 5개 컴포넌트로 구성
    - 웹 서버 : 파이썬 Flask로 구성
    - 스케줄러 
    - 워커 : task를 실행해주는 모듈
    - 메타 데이터 DB : 워커, 데이터 파이프라인 정보를 기억하는 DB, Sqlite가 기본으로 설치
    - 큐 : 다수의 서버로 airflow를 구성할 때 주로 사용하나 executor에 따라 싱글서버에서도 사용
- Airflow 구성
    - 스케쥴러는 DAG안에 Task들을 워커들에게 배정하는 역할을 수행
    - 웹 UI는 스케줄러와 DAG의 실행 상황을 시각화해줌
    - 워커는 실제로 DAG를 실행하는 역할을 수행
    - 스케줄러와 DAG 실행결과는 별도 DB에 저장
- Executor : 스케쥴러가 워커에 일을 줄 때 작동하는 다양한 방식
    - Sequential Executor : 디폴트, sqlite하고만 연동
    - Local Executor : 기본으로 많이 사용하고 실습할 때 사용함
